{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Jupyter Notebook for Illumination Flat Field\n",
    "Authors: Tony Sohn, Jo Taylor\n",
    "\n",
    "This notebook performs analysis for NIS-011a and creates a delta flat file. \n",
    "\n",
    "The input is either uncal files, which are then calibrated, or cal files which are directly used for analysis. Sources are identified in the cal files, then photometry is performed on each source in each dither pointing. Sources between each pointing are matched and the differences in their flux measurements are used to derive the delta flat. 2D fits are performed on flux ratios and the evaluated 2D fit is output as the delta flat file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:01.977Z",
     "iopub.status.busy": "2021-04-26T20:17:01.967Z",
     "iopub.status.idle": "2021-04-26T20:17:01.990Z",
     "shell.execute_reply": "2021-04-26T20:17:02.134Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import all needed packages\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import jwst\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Image2Pipeline\n",
    "from jwst.pipeline import Image3Pipeline\n",
    "import asdf\n",
    "\n",
    "import astropy\n",
    "from astropy import units as u\n",
    "from astropy.nddata import Cutout2D, NDData\n",
    "from astropy.stats import gaussian_sigma_to_fwhm, sigma_clipped_stats\n",
    "from astropy.table import Table, hstack\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.modeling.fitting import LevMarLSQFitter\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.io import ascii\n",
    "\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as opt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from astropy.stats import sigma_clip\n",
    "\n",
    "import photutils\n",
    "from photutils import EPSFBuilder, find_peaks\n",
    "from photutils.aperture import aperture_photometry, CircularAperture, CircularAnnulus, RectangularAperture, RectangularAnnulus\n",
    "from photutils.detection import DAOStarFinder, IRAFStarFinder\n",
    "from photutils.psf import DAOGroup, IntegratedGaussianPRF, extract_stars, IterativelySubtractedPSFPhotometry\n",
    "from photutils.background import MMMBackground, SExtractorBackground, ModeEstimatorBackground, MedianBackground\n",
    "from photutils.background import MADStdBackgroundRMS\n",
    "from photutils.centroids import centroid_2dg\n",
    "from photutils.utils import calc_total_error\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import style, pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.gridspec import GridSpec\n",
    "params={'legend.fontsize':'18','axes.labelsize':'18',\n",
    "        'axes.titlesize':'18','xtick.labelsize':'18',\n",
    "        'ytick.labelsize':'18','lines.linewidth':2,\n",
    "        'axes.linewidth':2,'animation.html': 'html5',\n",
    "        'figure.figsize':(15,15)}\n",
    "plt.rcParams.update(params)\n",
    "# Colorblind-safe palette below\n",
    "colors = [\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\", \"#a6cee3\", \"#1f78b4\", \"#b2df8a\", \"#33a02c\", \"#fb9a99\", \"#e31a1c\", \"#fdbf6f\", \"#ff7f00\", \"#cab2d6\", \"#6a3d9a\", \"#ffff99\", \"#b15928\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print package versions\n",
    "print(f'jwst: {jwst.__version__}')\n",
    "print(f'astropy: {astropy.__version__}')\n",
    "print(f'numpy: {np.__version__}')\n",
    "print(f'photutils: {photutils.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input files and calibrate if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<u><b>USER INPUT</b></u>\n",
    "    \n",
    "You need to define the following variables:\n",
    "* `testing`: If True, only use 3 pointings of the F150W filter. If False, full suite of files will be used.\n",
    "* `start_uncal`: True if starting from uncal files and you want to calibrate them within jupyter (this will take a LONG time!), False if starting from cal files. \n",
    "* `data_dir`: Directory that holds either uncal or cal files.\n",
    "* `outdir`: Directory to write output files to.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False # should be either True or False\n",
    "\n",
    "start_uncal = False # should be either True or False\n",
    "\n",
    "data_dir = \"/ifs/jwst/wit/niriss/cap_simulations/nis011a/out_24May21/\"\n",
    "outdir = os.path.join(os.getcwd(), \"out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it does not exist yet\n",
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "# Instantiate the ref images dictionary\n",
    "ref_ims = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting from uncal (can still be run if starting from cal)\n",
    "This may take a while depending on the number of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:02.011Z",
     "iopub.status.busy": "2021-04-26T20:17:02.002Z",
     "iopub.status.idle": "2021-04-26T20:17:02.023Z",
     "shell.execute_reply": "2021-04-26T20:17:02.139Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if start_uncal is True:\n",
    "    # Get all uncal files\n",
    "    # If testing just use 3 uncal files\n",
    "    if testing is True:\n",
    "        uncals = [os.path.join(data_dir, x) for x in [\"jw01086001001_01101_00021_nis_uncal.fits\", \"jw01086001001_01101_00045_nis_uncal.fits\", \"jw01086001001_01101_00069_nis_uncal.fits\"]]\n",
    "    else:\n",
    "        uncals = glob.glob(os.path.join(data_dir, \"*_uncal.fits\"))\n",
    "\n",
    "    # Modify Image2 parameter ref file to skip photom and resample\n",
    "    step = Image2Pipeline()\n",
    "    step.export_config('calwebb_image2.asdf')\n",
    "    af = asdf.open(\"calwebb_image2.asdf\")\n",
    "    for i,dct in enumerate(af.tree[\"steps\"]):\n",
    "        if dct[\"name\"] in [\"photom\", \"resample\", \"background\"]:\n",
    "            af.tree[\"steps\"][i][\"parameters\"][\"skip\"] = True\n",
    "    new_config = os.path.join(outdir, \"calwebb_image3.asdf\")\n",
    "    af.write_to(new_config)\n",
    "\n",
    "    # Put all files in data dictionary\n",
    "    data_d = collections.defaultdict(dict)\n",
    "    for item in uncals:\n",
    "        det1_out = Detector1Pipeline.call(item, save_results=True, output_dir=outdir)\n",
    "        im2_out = Image2Pipeline.call(det1_out, save_results=True, config_file=new_config, output_dir=outdir)\n",
    "        im2_file = os.path.join(outdir, image2[0].meta.filename)\n",
    "        filt = fits.getval(item, \"filter\")\n",
    "        pupil = fits.getval(item, \"pupil\")\n",
    "        filt = f'{filt}_{pupil}'\n",
    "        photmjsr = im2_out.meta.photometry.conversion_megajanskys\n",
    "        #print(f\"\\tConversion factor for DN/s to MJy/Sr: {photmjsr}\")\n",
    "        data_cps = im2_out.data/photmjsr\n",
    "        xoffset = im2_out.meta.dither.x_offset\n",
    "        yoffset = im2_out.meta.dither.y_offset\n",
    "        if xoffset == yoffset == 0.0:\n",
    "            ref_ims[filt] = im2_file\n",
    "        data_d[filt][im2_file] = {\"calfile\": im2_file, \"cal_datamodel\": im2_out, \"data_cps\": data_cps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting from cal files (can still be run if starting from uncal)\n",
    "This may take a while depending on the number of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_uncal is False:\n",
    "    # Get all cal files\n",
    "    # If testing just use 3 cal files\n",
    "    if testing is True:\n",
    "        cals = [os.path.join(data_dir, x) for x in [\"jw01086001001_01101_00021_nis_cal.fits\", \"jw01086001001_01101_00045_nis_cal.fits\", \"jw01086001001_01101_00069_nis_cal.fits\"]]\n",
    "    else:\n",
    "        cals = glob.glob(os.path.join(data_dir, \"*_cal.fits\"))\n",
    "\n",
    "    # Put all files in data dictionary\n",
    "    data_d = collections.defaultdict(dict)\n",
    "    for im2_file in cals:\n",
    "        filt = fits.getval(im2_file, \"filter\")\n",
    "        pupil = fits.getval(im2_file, \"pupil\")\n",
    "        filt = f'{filt}_{pupil}'\n",
    "        im2_out = datamodels.open(im2_file)\n",
    "        photmjsr = im2_out.meta.photometry.conversion_megajanskys\n",
    "        #print(f\"\\tConversion factor for DN/s to MJy/Sr: {photmjsr}\")\n",
    "        data_cps = im2_out.data/photmjsr\n",
    "        xoffset = im2_out.meta.dither.x_offset\n",
    "        yoffset = im2_out.meta.dither.y_offset\n",
    "        if xoffset == yoffset == 0.0:\n",
    "            ref_ims[filt] = im2_file\n",
    "        data_d[filt][im2_file] = {\"calfile\": im2_file, \"cal_datamodel\": im2_out, \"data_cps\": data_cps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The format of the data dictionary\n",
    "\n",
    "The data dictionary contains all necessary info for each filter and file in a nested format. Each key of `data_d` is the pupil and filter combo of the form <filt_pupil>, which is itself a dictionary. Each key of the filter dictionary is a file, which is itself a dictionary that stores all relevant info for each file such as the cal file's datamodel (`cal_datamodel`), the photometry for each aperture size (e.g. `phot_ap3`) and source catalog (`sources`). So if you wanted to see the source catalog for the F150W file `file1.fits` you would do that like so:\n",
    "```\n",
    "data_d['CLEAR_F150W']['file1.fits']['sources']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:02.225Z",
     "iopub.status.busy": "2021-04-26T20:17:02.218Z",
     "iopub.status.idle": "2021-04-26T20:17:02.755Z",
     "shell.execute_reply": "2021-04-26T20:17:02.802Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the reference image for each filter\n",
    "for filt,filt_d in data_d.items():\n",
    "    fname = ref_ims[filt]\n",
    "    file_d = filt_d[fname]\n",
    "    data_cps = file_d[\"data_cps\"]\n",
    "    normlzd = simple_norm(data_cps, 'sqrt', percent=99.)\n",
    "    plt.xlabel(\"X [pix]\")\n",
    "    plt.ylabel(\"Y [pix]\")\n",
    "    plt.imshow(data_cps, norm=normlzd, cmap=\"Greys\", origin='lower')\n",
    "    plt.title(f\"{filt.upper()} reference, {os.path.basename(fname)}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Sources\n",
    "This can take some time depending on number of files, up to 10s per file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:02.776Z",
     "iopub.status.busy": "2021-04-26T20:17:02.768Z",
     "iopub.status.idle": "2021-04-26T20:17:09.518Z",
     "shell.execute_reply": "2021-04-26T20:17:09.557Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Estimate background and identify stars to be used for building PSF via photutils tasks \n",
    "# The parameters below work generally well for NIRISS images\n",
    "\n",
    "bkgrms = MADStdBackgroundRMS()\n",
    "mmm_bkg = MMMBackground()\n",
    "\n",
    "# Define parameters for each image, in case we want to tweak params for certain exposures\n",
    "# Right now, just use same params for all images\n",
    "for filt,filt_d in data_d.items():\n",
    "    print(filt)\n",
    "    for fname,file_d in filt_d.items():\n",
    "        data_cps = file_d[\"data_cps\"]\n",
    "        std = bkgrms(data_cps)\n",
    "        bkg = mmm_bkg(data_cps)\n",
    "        starfinder = IRAFStarFinder(threshold=100*std + bkg, fwhm=2.0, minsep_fwhm=7, \n",
    "                                    roundlo=0.0, roundhi=0.6, sharplo=0.6, sharphi=1.4)\n",
    "        sources = starfinder(data_cps)\n",
    "        file_d[\"sources\"] = sources\n",
    "        print(fname)\n",
    "        print(f\"\\tBackground: {bkg:.4f}, StdDev: {std:4f}, Sources: {len(sources)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:09.538Z",
     "iopub.status.busy": "2021-04-26T20:17:09.530Z",
     "iopub.status.idle": "2021-04-26T20:17:09.791Z",
     "shell.execute_reply": "2021-04-26T20:17:09.831Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect plots like below to make sure we're picking up most of the stars while avoiding junk\n",
    "# Only plot reference images\n",
    "for filt,fname in ref_ims.items():\n",
    "    file_d = data_d[filt][fname]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20,7))\n",
    "    sources = file_d[\"sources\"]\n",
    "        \n",
    "    axes[0].plot(sources['mag'], sources['sharpness'], 'o', color=colors[0], markersize=3)\n",
    "    axes[0].set_xlabel('Magnitude')\n",
    "    axes[0].set_ylabel('Sharpness')\n",
    "    axes[0].set_title(f\"{filt.upper()}, {os.path.basename(fname)}\")\n",
    "        \n",
    "    axes[1].plot(sources['mag'], sources['roundness'], 'o', color=colors[1], markersize=3)\n",
    "    axes[1].set_xlabel('Magnitude')\n",
    "    axes[1].set_ylabel('Roundness')\n",
    "    axes[1].set_title(f\"{filt.upper()} reference, {os.path.basename(fname)}\")\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20,7))\n",
    "    ax.plot(sources['flux'], sources['fwhm'], 'o', color=colors[2], markersize=3)\n",
    "    ax.set_xlabel(\"FWHM\")\n",
    "    ax.set_ylabel(\"Flux\")\n",
    "    ax.set_title(f\"{filt.upper()} reference, {os.path.basename(fname)}\")\n",
    "    ax.set_xlim(-100, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<u><b>USER INPUT</b></u>\n",
    "    \n",
    "You need to define the following variables:\n",
    "* `all_fwhm_lims`: The minimum and maximum limits for the FWHM for each filter, use diagnostic plots above.\n",
    "* `all_flux_lims`: The minimum and maximum limits for the flux for each filter, use diagnostic plots above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't use the upper flux limit for now, so just edit lower limit\n",
    "all_flux_lims = {\n",
    "'F430M_CLEARP': [20, 1000],\n",
    "'CLEAR_F090W': [50, 1000],\n",
    "'CLEAR_F200W': [50, 1000],\n",
    "'F356W_CLEARP': [50, 1000],\n",
    "'F444W_CLEARP': [50, 1000],\n",
    "'F277W_CLEARP': [50, 1000],\n",
    "'CLEAR_F140M': [50, 1000],\n",
    "'CLEAR_F115W': [50, 1000],\n",
    "'F380M_CLEARP': [20, 1000],\n",
    "'CLEAR_F158M': [50, 1000],\n",
    "'CLEAR_F150W': [50, 1000],\n",
    "'F480M_CLEARP': [20, 1000],\n",
    "}\n",
    "\n",
    "all_fwhm_lims = {\n",
    "'F430M_CLEARP': [1.6, 1.9],\n",
    "'CLEAR_F090W': [1.1, 1.6],\n",
    "'CLEAR_F200W': [1.1, 1.6],\n",
    "'F356W_CLEARP': [1.3, 1.7],\n",
    "'F444W_CLEARP': [1.5, 2.0],\n",
    "'F277W_CLEARP': [1.1, 1.6],\n",
    "'CLEAR_F140M': [1.1, 1.6],\n",
    "'CLEAR_F115W': [1.1, 1.6],\n",
    "'F380M_CLEARP': [1.4, 1.8],\n",
    "'CLEAR_F158M': [1.1, 1.8],\n",
    "'CLEAR_F150W': [1.1, 1.6],\n",
    "'F480M_CLEARP': [1.6, 2.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for filt,fname in ref_ims.items():\n",
    "    file_d = data_d[filt][fname]\n",
    "    sources = file_d[\"sources\"]\n",
    "        \n",
    "    flux_lims = all_flux_lims[filt]\n",
    "    fwhm_lims = all_fwhm_lims[filt]\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.plot(sources['flux'], sources['fwhm'], 'o', color=colors[2], markersize=3)\n",
    "    plt.xlim(0, 1000)\n",
    "    plt.plot([flux_lims[0], flux_lims[0]], [fwhm_lims[0], fwhm_lims[1]], color=colors[1])\n",
    "    plt.plot([flux_lims[0], 1000], [fwhm_lims[1], fwhm_lims[1]], color=colors[1])\n",
    "    plt.plot([flux_lims[0], 1000], [fwhm_lims[0], fwhm_lims[0]], color=colors[1])\n",
    "    plt.title(f\"{filt.upper()} reference, {os.path.basename(fname)}\")\n",
    "    plt.xlabel(\"Flux\")\n",
    "    plt.ylabel(\"FWHM\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:09.918Z",
     "iopub.status.busy": "2021-04-26T20:17:09.910Z",
     "iopub.status.idle": "2021-04-26T20:17:22.774Z",
     "shell.execute_reply": "2021-04-26T20:17:22.849Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# From the plot above, you can find the FWHM and flux limits of good sources\n",
    "# Apply these filters (or masks) and overplot the detected sources on the \n",
    "# image to make sure we're dealing with actual stars\n",
    "for filt,filt_d in data_d.items():\n",
    "    for fname,file_d in filt_d.items():\n",
    "        flux_lims = all_flux_lims[filt]\n",
    "        fwhm_lims = all_fwhm_lims[filt]\n",
    "        sources = file_d[\"sources\"]\n",
    "        mask = (sources['fwhm'] > fwhm_lims[0]) & (sources['fwhm'] < fwhm_lims[1]) & (sources['flux'] > flux_lims[0]) \n",
    "        sources_masked = sources[mask]\n",
    "        file_d[\"sources_masked\"] = sources_masked\n",
    "        positions = np.transpose((sources_masked['xcentroid'], sources_masked['ycentroid']))\n",
    "        apertures = CircularAperture(positions, r=10)\n",
    "        normlzd = simple_norm(file_d[\"data_cps\"], 'sqrt', percent=99.)\n",
    "        \n",
    "        if fname == ref_ims[filt]:\n",
    "            plt.imshow(file_d[\"data_cps\"], norm=normlzd, cmap='Greys', origin='lower')\n",
    "            apertures.plot(color='blue', lw=1.5, alpha=0.5)\n",
    "            plt.xlabel(\"X [pix]\")\n",
    "            plt.ylabel(\"Y [pix]\")\n",
    "            plt.title(f\"{filt.upper()} reference: {os.path.basename(fname)}\")\n",
    "        \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform aperture photometry\n",
    "This can take some time, depending on number of aperture sizes and files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<u><b>USER INPUT</b></u>\n",
    "    \n",
    "You need to define the following variables:\n",
    "* `aperture_sizes`: The list of aperture sizes to try, e.g. `[3, 5, 7, 10]`\n",
    "* `annulus_offset`: The offset from the aperture size to use for the inner and outer radius of the sky annulus, e.g. `[+3, +7]`\n",
    "    \n",
    "Not yet implemented: use isolated bright, but non-saturated, stars to determine the best aperture size.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aperture and annulus sizes\n",
    "aperture_sizes = [3]\n",
    "annulus_offset = [+3, +7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:29.806Z",
     "iopub.status.busy": "2021-04-26T20:17:29.797Z",
     "iopub.status.idle": "2021-04-26T20:17:32.819Z",
     "shell.execute_reply": "2021-04-26T20:17:32.861Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Now perform aperture photometry on the stars\n",
    "for filt,filt_d in data_d.items():\n",
    "    for fname,file_d in filt_d.items():\n",
    "        sources_masked = file_d[\"sources_masked\"]\n",
    "        positions = np.transpose((sources_masked['xcentroid'], sources_masked['ycentroid']))\n",
    "        for ap_size in aperture_sizes:\n",
    "            apertures = CircularAperture(positions, r=ap_size)\n",
    "            annulus_apertures = CircularAnnulus(positions, \n",
    "                                                r_in=ap_size+annulus_offset[0], \n",
    "                                                r_out=ap_size+annulus_offset[1])\n",
    "            annulus_masks = annulus_apertures.to_mask(method='center')\n",
    "            bkg_median = []\n",
    "            for mask in annulus_masks:\n",
    "                annulus_data = mask.multiply(file_d[\"data_cps\"])\n",
    "                annulus_data_1d = annulus_data[mask.data > 0]\n",
    "                _, median_sigclip, _ = sigma_clipped_stats(annulus_data_1d)\n",
    "                bkg_median.append(median_sigclip)\n",
    "            bkg_median = np.array(bkg_median)\n",
    "            phot = aperture_photometry(file_d[\"data_cps\"], apertures)\n",
    "            phot['annulus_median'] = bkg_median\n",
    "            phot['aper_bkg'] = bkg_median * apertures.area\n",
    "            phot['aper_sum_bkgsub'] = phot['aperture_sum'] - phot['aper_bkg']\n",
    "            file_d[f\"phot_ap{ap_size}\"] = phot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:35.756Z",
     "iopub.status.busy": "2021-04-26T20:17:35.747Z",
     "iopub.status.idle": "2021-04-26T20:17:35.771Z",
     "shell.execute_reply": "2021-04-26T20:17:35.962Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# From Kevin Volk's email sent to Tony on Mar 26, 2021\n",
    "# Assumed A0V spectral template: Bohlin Sirius (2020)\n",
    "\n",
    "niriss_info = \"\"\"\n",
    "#                        ADU/sec           Jy          Microns    (MJy/ster)/(ADU/s)      Jy/(ADU/s)\n",
    "ins    filter         count_rate     mean_f_nu        pivot_wl      phot_mjsr          phot_jy\n",
    "NIRISS F090W          2.804222e+11   8.371777e+03     0.902458      1.673899e-10       2.985419e-08\n",
    "NIRISS F115W          2.347116e+11   6.508594e+03     1.149542      1.554807e-10       2.773018e-08\n",
    "NIRISS F140M          7.340864e+10   4.757672e+03     1.404035      3.633885e-10       6.481080e-08\n",
    "NIRISS F150W          1.391529e+11   4.346497e+03     1.493457      1.751341e-10       3.123539e-08\n",
    "NIRISS F158M          6.487924e+10   3.939552e+03     1.582011      3.404590e-10       6.072129e-08\n",
    "NIRISS F200W          9.570604e+10   2.755850e+03     1.992961      1.614508e-10       2.879494e-08\n",
    "NIRISS F277W          5.573678e+10   1.575708e+03     2.764281      1.585104e-10       2.827052e-08\n",
    "NIRISS F356W          3.667514e+10   9.791757e+02     3.593004      1.496969e-10       2.669862e-08\n",
    "NIRISS F380M          6.607656e+09   8.561057e+02     3.825227      7.264468e-10       1.295627e-07\n",
    "NIRISS F430M          4.290003e+09   6.923615e+02     4.283827      9.048971e-10       1.613895e-07\n",
    "NIRISS F444W          2.242869e+10   6.615412e+02     4.427699      1.653776e-10       2.949531e-08\n",
    "NIRISS F480M          3.839979e+09   5.582376e+02     4.815243      8.151061e-10       1.453752e-07\n",
    "Guider 1              1.379334e+12   4.478894e+03     2.501078      1.684581e-11       3.247142e-09\n",
    "Guider 2              1.604525e+12   4.291017e+03     2.591652      1.386584e-11       2.674322e-09\n",
    "\"\"\"\n",
    "\n",
    "t = ascii.read(niriss_info, data_start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:35.796Z",
     "iopub.status.busy": "2021-04-26T20:17:35.787Z",
     "iopub.status.idle": "2021-04-26T20:17:35.818Z",
     "shell.execute_reply": "2021-04-26T20:17:35.967Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the star magnitudes and coordinates for each aperture size\n",
    "for filt,filt_d in data_d.items():\n",
    "    filt0, pup0 = filt.split(\"_\")\n",
    "    if filt0 in [\"CLEAR\", \"CLEARP\"]:\n",
    "        filtkey = pup0\n",
    "    else:\n",
    "        filtkey = filt0\n",
    "    # Magnitude zero points defined using the table above.\n",
    "    count_rate = t[t['filter'] == filtkey.upper()]['count_rate'][0]\n",
    "    zpt = 2.5 * np.log10(count_rate)\n",
    "    for i,(fname,file_d) in enumerate(filt_d.items()):\n",
    "        for ap_size in aperture_sizes:\n",
    "            phot = file_d[f\"phot_ap{ap_size}\"]\n",
    "        #phot = file_d[phot_ap]\n",
    "            phot['mag'] = -2.5 * np.log10(phot['aper_sum_bkgsub']) + zpt - 1.401 # where does 1.401 come from?\n",
    "            phot['mag_err'] = 1.0857 * np.sqrt(phot['aper_sum_bkgsub']) / phot['aper_sum_bkgsub'] # where does 1.0857 come from?\n",
    "\n",
    "            # Convert the detected positions into sky coordinates (RA, Dec) in degrees\n",
    "            detector_to_world = file_d[\"cal_datamodel\"].meta.wcs.get_transform('detector', 'world')\n",
    "            ra, dec = detector_to_world(phot[\"xcenter\"].value, phot[\"ycenter\"]  .value)\n",
    "            phot[\"ra_deg\"] = ra\n",
    "            phot[\"dec_deg\"] = dec\n",
    "            coords = SkyCoord(ra=ra*u.degree, dec=dec*u.degree, frame='icrs')\n",
    "            phot['coords'] = coords\n",
    "\n",
    "            # At this stage, let's save the resulting photometry table to files so we don't have to \n",
    "            # repeat all the steps above in case something goes wrong with this session\n",
    "            photfile0 = os.path.basename(fname).replace(\".fits\", f\"_photutils_ap{ap_size}.fits\")\n",
    "            photfile = os.path.join(outdir, photfile0)\n",
    "            phot.write(photfile, format=\"fits\", overwrite=True)\n",
    "            #print(f\"Wrote {photfile}\")\n",
    "\n",
    "        # Let's take a look at how the sky coordinates look like for each catalog\n",
    "        plt.plot(ra, dec, '<', color=colors[i], alpha=0.5, \n",
    "                 label=os.path.basename(fname))\n",
    "        plt.title(filt.upper())\n",
    "        plt.legend(bbox_to_anchor=(-.15, 1.35), loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<u><b>USER INPUT</b></u>\n",
    "    \n",
    "You need to define the following variables:\n",
    "* `ap_use`: The aperture size to use for all photometry going forward.\n",
    "    \n",
    "Not yet implemented: use isolated bright, but non-saturated, stars to determine the best aperture size.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do: Need to let this vary as a function of filter\n",
    "ap_use = 3 # 3 5 7 10\n",
    "phot_ap = f'phot_ap{ap_use}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match stars in each image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:36.038Z",
     "iopub.status.busy": "2021-04-26T20:17:36.030Z",
     "iopub.status.idle": "2021-04-26T20:17:36.052Z",
     "shell.execute_reply": "2021-04-26T20:17:36.106Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now let's do the coordinate-based crossmatching\n",
    "# For this, we use the simple match_coordinates_sky method from astropy.coordinates\n",
    "# Just produce one group of plots per filter, since 8 sets is a little much!\n",
    "\n",
    "for filt,filt_d in data_d.items():\n",
    "    ref_im = ref_ims[filt]\n",
    "    phot0 = filt_d[ref_im][phot_ap]\n",
    "    filt_d[ref_im]['source_catalog'] = np.nan\n",
    "    plotted = False\n",
    "\n",
    "    for i,(fname,file_d) in enumerate(filt_d.items()):\n",
    "        if fname == ref_im:\n",
    "            continue\n",
    "        # Note: idx is the index of c1\n",
    "        photi = file_d[phot_ap]\n",
    "        idx, d2d, d3d = match_coordinates_sky(photi['coords'], phot0['coords'])\n",
    "        \n",
    "        d0 = {'ra_deg_ref': phot0['ra_deg'][idx], 'dec_deg_ref': phot0['dec_deg'][idx], \n",
    "              'x_ref': phot0['xcenter'][idx], 'y_ref': phot0['ycenter'][idx],\n",
    "              'mag_ref': phot0['mag'][idx], 'magerr_ref': phot0['mag_err'][idx], \n",
    "              'aper_sum_bkgsub_ref': phot0['aper_sum_bkgsub'][idx]}\n",
    "        t0 = Table(d0)\n",
    "                \n",
    "        di = {'ra_deg': photi['ra_deg'], 'dec_deg': photi['dec_deg'], \n",
    "              'x': photi['xcenter'], 'y': photi['ycenter'],\n",
    "              'mag': photi['mag'], 'magerr': photi['mag_err'],\n",
    "              'aper_sum_bkgsub': photi['aper_sum_bkgsub'],\n",
    "              'sep2d_arcsec': d2d.arcsecond}\n",
    "        ti = Table(di)\n",
    "        ti0 = hstack([t0, ti])\n",
    "        file_d['source_catalog'] = ti0\n",
    "        \n",
    "        if plotted is True:\n",
    "            continue\n",
    "            \n",
    "        print(filt)\n",
    "        print(f\"Ref:        {ref_im}\")\n",
    "        print(f\"Comparison: {fname}\")\n",
    "        # Inspect the distance between matched sources to find out how to select good sources.\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        axes[0].hist(d2d.arcsecond, histtype='bar', facecolor=colors[0], linewidth=1.2, bins=50, range=(-0.1,1))\n",
    "        axes[0].set_xlabel(\"Separation (arcsec)\")\n",
    "        axes[0].set_ylabel(\"N\")\n",
    "    \n",
    "        # Also inspect difference in magnitudes.\n",
    "        dmag = photi['mag'] - phot0['mag'][idx]\n",
    "        axes[1].hist(dmag, histtype='bar', facecolor=colors[0], linewidth=1.2, bins=50, range=(-2,2))\n",
    "        axes[1].set_xlabel(\"Delta Mag\")\n",
    "        axes[1].set_ylabel(\"N\")\n",
    "        plt.show()\n",
    "        plotted = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<u><b>USER INPUT</b></u>\n",
    "    \n",
    "You need to define the following variables:\n",
    "* `sep_limit`: Any \"matched\" stars with separartion (arcsec) larger than this value will be ignored.\n",
    "    \n",
    "Not yet implemented: use isolated bright, but non-saturated, stars to determine the best aperture size.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 is a safe bet, might not need to change\n",
    "sep_limit = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T20:17:36.445Z",
     "iopub.status.busy": "2021-04-26T20:17:36.438Z",
     "iopub.status.idle": "2021-04-26T20:17:36.461Z",
     "shell.execute_reply": "2021-04-26T20:17:36.516Z"
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now filter out the bad matches and write the crossmatched catalog to a FITS table\n",
    "# Write an output file {filt}_crossmatched.fits with source measurements for ref and dither images\n",
    "# Just produce one group of plots per filter, since 8 sets is a little much!\n",
    "\n",
    "for filt,filt_d in data_d.items():\n",
    "    ref_im = ref_ims[filt]\n",
    "    plotted = False\n",
    "    for i,(fname,file_d) in enumerate(filt_d.items()):\n",
    "        if fname == ref_im:\n",
    "            file_d['filtered_dmag'] = np.nan\n",
    "            file_d['filtered_xref'] = np.nan\n",
    "            file_d['filtered_yref'] = np.nan\n",
    "            continue\n",
    "\n",
    "        ti0 = file_d['source_catalog']\n",
    "        mask = (ti0['sep2d_arcsec'] < sep_limit)\n",
    "        t_filtered = ti0[mask]\n",
    "        matched_file = os.path.join(outdir, f'{filt}_crossmatched_{i}.fits')\n",
    "        t_filtered.write(matched_file, format='fits', overwrite=True)\n",
    "        with fits.open(matched_file, mode='update') as hdulist:\n",
    "            hdr0 = hdulist[0].header\n",
    "            hdr0.set(\"ref_img\", ref_im)\n",
    "            hdr0.set(\"comp_img\", fname)\n",
    "        #print(f'Wrote {matched_file}')\n",
    "        \n",
    "        delx = t_filtered['x_ref'] - t_filtered['x']\n",
    "        dely = t_filtered['y_ref'] - t_filtered['y']\n",
    "        \n",
    "        # Calculate magnitude difference and flux ratio\n",
    "        dmag0 = t_filtered['mag_ref'] - t_filtered['mag']\n",
    "        dmag = dmag0.data\n",
    "        dmag = np.nan_to_num(dmag, nan=0)\n",
    "        flux_ratio0 = t_filtered['aper_sum_bkgsub_ref'] / t_filtered['aper_sum_bkgsub']\n",
    "        flux_ratio = flux_ratio0.data\n",
    "        flux_ratio = np.nan_to_num(flux_ratio, nan=0)        \n",
    "                \n",
    "        dmag_sigma_mask = sigma_clip(dmag, sigma=3, maxiters=10, masked=True)\n",
    "        filtered_dmag = dmag[~dmag_sigma_mask.mask]\n",
    "        file_d['filtered_dmag'] = filtered_dmag\n",
    "        \n",
    "        sigma_mask = sigma_clip(flux_ratio, sigma=3, maxiters=10, masked=True)\n",
    "        file_d['filtered_flux_ratio'] = flux_ratio[~sigma_mask.mask]\n",
    "        file_d['filtered_xref'] = t_filtered['x_ref'][~sigma_mask.mask]\n",
    "        file_d['filtered_yref'] = t_filtered['y_ref'][~sigma_mask.mask]\n",
    "        file_d['filtered_deltax'] = t_filtered['x_ref'][~sigma_mask.mask] - t_filtered['x'][~sigma_mask.mask]\n",
    "        file_d['filtered_deltay'] = t_filtered['y_ref'][~sigma_mask.mask] - t_filtered['y'][~sigma_mask.mask]\n",
    " \n",
    "        if plotted is True:\n",
    "            continue\n",
    "\n",
    "        print(filt)\n",
    "        print(f\"Ref:        {ref_im}\")\n",
    "        print(f\"Comparison: {fname}\")\n",
    "        fig, axes0 = plt.subplots(2, 2, figsize=(20,20))\n",
    "        axes = axes0.flatten()\n",
    "\n",
    "        # Plot delta y vs delta x\n",
    "        axes[0].plot(delx, dely, 'o', color=colors[0], markersize=3.0)\n",
    "        axes[0].set_xlabel(\"Delta X\")\n",
    "        axes[0].set_ylabel(\"Delta Y\")\n",
    "\n",
    "        # Plot histogram of delta mags\n",
    "        axes[1].hist(dmag, color=colors[0], density=True, linewidth=1.2, bins=500, range=[-0.2,0.2], label=\"Data\")\n",
    "        # Fit Gaussian to delta mag\n",
    "        mu1, std1 = norm.fit(dmag)\n",
    "        x1 = np.linspace(-.2, .2, 500)\n",
    "        p1 = norm.pdf(x1, mu1, std1)\n",
    "        axes[1].plot(x1, p1, colors[1], linewidth=5, label=\"Guassian Fit\")\n",
    "        axes[1].legend(loc=\"best\")\n",
    "        axes[1].set_xlabel(\"Delta Mag\")\n",
    "        axes[1].set_ylabel(\"N\")\n",
    "\n",
    "        # Plot histogram of sigma-clipped delta mags\n",
    "        axes[2].hist(filtered_dmag, bins=100, density=True, color=colors[0], label=\"Data\")\n",
    "        mu, std = norm.fit(filtered_dmag)\n",
    "        xmin = np.min(filtered_dmag)\n",
    "        xmax = np.max(filtered_dmag)\n",
    "        x = np.linspace(xmin, xmax, 500)\n",
    "        p = norm.pdf(x, mu, std)\n",
    "        axes[2].plot(x, p, colors[1], linewidth=5, label=\"Guassian Fit\")\n",
    "        axes[2].axvline(0, linestyle=\"--\", color=\"k\")\n",
    "        axes[2].legend(loc=\"best\")\n",
    "        axes[2].set_xlabel(\"Sigma-clipped Delta Mag\")\n",
    "        axes[2].set_ylabel(\"N\")\n",
    "        \n",
    "        axes[3].hist(file_d['filtered_flux_ratio'], bins=100, color=colors[0])\n",
    "        axes[3].set_xlim(.5, 1.5)\n",
    "        axes[3].set_xlabel(\"Flux Ratio\")\n",
    "        axes[3].set_ylabel(\"N\")\n",
    "\n",
    "        plt.show()\n",
    "        plotted = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all flux ratio measurements as a function of ref. image X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master x_ref, y_ref, and dmag arrays\n",
    "# From here on, we do not loop over any files, just filters\n",
    "final_data = {}\n",
    "for filt,filt_d in data_d.items():\n",
    "    x_ref = np.array([])\n",
    "    y_ref = np.array([])\n",
    "    z = np.array([])\n",
    "    final_data[filt] = {}\n",
    "    ref_im = ref_ims[filt]\n",
    "    for fname,file_d in filt_d.items():\n",
    "        if fname == ref_im:\n",
    "            continue\n",
    "        x_ref = np.concatenate((x_ref, file_d['filtered_xref']))\n",
    "        y_ref = np.concatenate((y_ref, file_d['filtered_yref']))\n",
    "        z = np.concatenate((z, file_d['filtered_flux_ratio']))\n",
    "        final_data[filt]['x_ref'] = x_ref\n",
    "        final_data[filt]['y_ref'] = y_ref\n",
    "        final_data[filt]['flux_ratio'] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make 2D plot of average ratios for diagnostic purposes only, this might help you decide which fit to use\n",
    "# Bin x and y data into an image\n",
    "# From: https://stackoverflow.com/questions/30764955/python-numpy-create-2d-array-of-values-based-on-coordinates\n",
    "for filt,filt_d in final_data.items():\n",
    "    zi, yi, xi = np.histogram2d(filt_d['y_ref'], filt_d['x_ref'], bins=(2048,2048), \n",
    "                                weights=filt_d['flux_ratio'], normed=False)\n",
    "    counts, _, _ = np.histogram2d(filt_d['y_ref'], filt_d['x_ref'], bins=(2048,2048))\n",
    "    zi /= counts\n",
    "    ratio_im = np.nan_to_num(zi, nan=1)\n",
    "    im = plt.imshow(ratio_im, origin=\"lower\", vmin=.999, vmax=1.001)\n",
    "    plt.colorbar(im, label=\"Flux Ratio\")\n",
    "    plt.title(f\"{filt}, average flux ratio of all pointings\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit variety of models to flux ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<u><b>USER INPUT</b></u>\n",
    "    \n",
    "You need to define the following variables:\n",
    "* `init_guess`: Initial guess for the 2D Gaussian fit parameters. Corresponds to amplitude, xo, yo, sigma_x, sigma_y, theta, offset. If you're not interested in fitting a Gaussian, you can leave this as is.\n",
    "\n",
    "**WARNING!!!** Fitting a 2D gaussian is difficult. Derived fits will be inaccurate unless you provide an initial guess for the parameters- use the plots above to estimate the initial guess.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponds to amplitude, xo, yo, sigma_x, sigma_y, theta, offset\n",
    "init_guess = (1.2, 1250, 1250, 200, 500, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model function for a 2D Gaussian that can be fit\n",
    "# From: https://stackoverflow.com/questions/21566379/fitting-a-2d-gaussian-function-using-scipy-optimize-curve-fit-valueerror-and-m\n",
    "def twod_gaussian(xy, amplitude, xo, yo, sigma_x, sigma_y, theta, offset):\n",
    "    x = xy[0]\n",
    "    y = xy[1]\n",
    "    xo = float(xo)\n",
    "    yo = float(yo)    \n",
    "    a = (np.cos(theta)**2)/(2*sigma_x**2) + (np.sin(theta)**2)/(2*sigma_y**2)\n",
    "    b = -(np.sin(2*theta))/(4*sigma_x**2) + (np.sin(2*theta))/(4*sigma_y**2)\n",
    "    c = (np.sin(theta)**2)/(2*sigma_x**2) + (np.cos(theta)**2)/(2*sigma_y**2)\n",
    "    g = offset + amplitude*np.exp( - (a*((x-xo)**2) + 2*b*(x-xo)*(y-yo) + c*((y-yo)**2)))\n",
    "    return g.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit 2D polynomial, legendre, and chebyshev functions of the orders specified below. Also fit a 2D gaussian.\n",
    "orders = [1, 2, 3, 4, 5]\n",
    "for filt,filt_d in final_data.items():\n",
    "    actualx = filt_d['x_ref']\n",
    "    actualy = filt_d['y_ref']\n",
    "    actualz = filt_d['flux_ratio']\n",
    "    fts = {}\n",
    "    for i in orders:\n",
    "        poly = models.Polynomial2D(degree=i)\n",
    "        leg = models.Legendre2D(x_degree=i, y_degree=i)\n",
    "        cheby = models.Chebyshev2D(x_degree=i, y_degree=i)  \n",
    "        fitter = LevMarLSQFitter()\n",
    "        poly_fit = fitter(poly, actualx, actualy, actualz)\n",
    "        leg_fit = fitter(leg, actualx, actualy, actualz)\n",
    "        cheby_fit = fitter(cheby, actualx, actualy, actualz)\n",
    "        fts[f'polynomial order={i}'] = poly_fit\n",
    "        fts[f'legendre order={i}'] = leg_fit\n",
    "        fts[f'chebyshev order={i}'] = cheby_fit\n",
    "    popt, pcov = opt.curve_fit(twod_gaussian, (actualx, actualy), actualz, p0=init_guess)\n",
    "    fts['2d gaussian'] = popt\n",
    "    filt_d['fts'] = fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now evaluate each fit and estimate its goodness\n",
    "x = y = np.arange(2048)\n",
    "for filt,filt_d in final_data.items():\n",
    "    print(filt)\n",
    "    fts = filt_d['fts']\n",
    "    for fitname,fit in fts.items():\n",
    "        if fitname == \"2d gaussian\":\n",
    "            fit_z = twod_gaussian((actualx, actualy), *fit)\n",
    "        else:\n",
    "            fit_z = fit(actualx, actualy)\n",
    "        rmse = mean_squared_error(actualz, fit_z, squared=False)\n",
    "        chi2 = np.sum( (actualz-fit_z)**2 / fit_z )\n",
    "        print(fitname)\n",
    "        print(f'\\tRMSE:{rmse:.5f}, Chi2: {chi2:.4f}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<u><b>USER INPUT</b></u>\n",
    "    \n",
    "You need to define the following variables:\n",
    "* `final_fitname`: The name of the fit to adopt for the delta flat. This assumes the same fit will be used for all filters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fitname = 'polynomial order=3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a 3D plot of the flux ratios and overplot the fit surface\n",
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "xmesh, ymesh = np.meshgrid(x, y)\n",
    "for filt,filt_d in final_data.items():\n",
    "    print(filt)\n",
    "    fts = filt_d['fts']\n",
    "    final_fit = fts[final_fitname]\n",
    "    # Evaluate the fit on an integer grid for plotting below    \n",
    "    if final_fitname == \"2d gaussian\":    \n",
    "        zmesh = twod_gaussian((xmesh, ymesh), *final_fit)\n",
    "        zmesh = zmesh.reshape(2048, 2048)\n",
    "    else:\n",
    "        zmesh = final_fit(xmesh, ymesh)\n",
    "    filt_d['fit_zmesh'] = zmesh\n",
    "    fig = plt.figure(figsize=(15,15)) \n",
    "    ax = fig.add_subplot(111,projection='3d')\n",
    "    ax.scatter(actualx, actualy, actualz, marker='o', s=15, c=colors[0])\n",
    "    downsample = 10\n",
    "    ax.plot_surface(xmesh, ymesh, zmesh, rcount=downsample, ccount=downsample, color=colors[1], \n",
    "                    shade=False, alpha=0.3)\n",
    "    ax.set_zlim(0, 2)\n",
    "    ax.set_title(filt)\n",
    "    ax.set_xlabel(\"X pixel\")\n",
    "    ax.set_ylabel(\"Y pixel\")\n",
    "    ax.set_zlabel(\"Flux ratio\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to do this to undo the 3D plotting capabilities\n",
    "%matplotlib inline\n",
    "from matplotlib import style, pyplot as plt\n",
    "params={'legend.fontsize':'18','axes.labelsize':'18',\n",
    "        'axes.titlesize':'18','xtick.labelsize':'18',\n",
    "        'ytick.labelsize':'18','lines.linewidth':2,\n",
    "        'axes.linewidth':2,'animation.html': 'html5',\n",
    "        'figure.figsize':(15,15)}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now plot the fit in 2D\n",
    "for filt,filt_d in final_data.items():\n",
    "    mn = 1. - np.min(filt_d['fit_zmesh'].flatten())\n",
    "    mx = 1. - np.max(filt_d['fit_zmesh'].flatten())\n",
    "    mx_mx = np.max(np.abs([mn, mx]))\n",
    "    im = plt.imshow(filt_d['fit_zmesh'], origin='lower', vmin=1.0-mx_mx, vmax=1.0+mx_mx, cmap=\"PiYG\")\n",
    "    plt.colorbar(im, label=\"Flux Ratio\")\n",
    "    plt.title(f'{filt} Delta Flat')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create delta flat file for each filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now package the data into a fits file. \n",
    "for filt,filt_d in final_data.items():\n",
    "    im = filt_d['fit_zmesh']\n",
    "    central = im[974:1075, 974:1075]\n",
    "    # Compute the mean in the central 100x100 pixels and use that to normalize the image.\n",
    "    #central = im[974:1075, 974:1075]\n",
    "    #avg = np.average(central)\n",
    "    avg = np.average(im)\n",
    "    nrmlzd = im/avg\n",
    "\n",
    "    outname0 = f'{filt}_deltaflat.fits'\n",
    "    outname = os.path.join(outdir, outname0)\n",
    "    \n",
    "    hdr0 = fits.Header()\n",
    "    filt0, pup0 = filt.split(\"_\")\n",
    "    hdr0['FILTER'] = filt0\n",
    "    hdr0['PUPIL'] = pup0\n",
    "    hdu0 = fits.PrimaryHDU(header=hdr0)\n",
    "    hdu1 = fits.ImageHDU(nrmlzd)\n",
    "    hdulist = fits.HDUList([hdu0, hdu1])\n",
    "    \n",
    "    hdulist.writeto(outname, overwrite=True)\n",
    "    print(f'Wrote file: {outname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
